{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import stellargraph as sg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "from tensorflow.keras import layers, Model, optimizers, losses, callbacks\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set edges\n",
    "edges = pd.read_table('../datasets/twitter/users.edges', header=None, sep=' ')\n",
    "edges.columns = ['source', 'target'] # should be follow this column name\n",
    "gx = nx.from_pandas_edgelist(edges) # stellar graph form\n",
    "\n",
    "# load features\n",
    "all_features = pd.read_table('../datasets/twitter/users_hate_all.content', header=None, index_col=0)\n",
    "all_features[321] = all_features[321].replace(['hateful', 'normal', 'other'], [0, 1, 2])\n",
    "features = all_features[all_features[321] != 2]\n",
    "target = all_features[all_features[321] != 2][321]\n",
    "all_features = all_features.drop(321, axis=1)\n",
    "\n",
    "# make graph\n",
    "G = sg.StellarGraph(gx, node_features=all_features)\n",
    "nodes = list(G.nodes())\n",
    "print(G.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_X, val_X, tr_target, val_target = model_selection.train_test_split(\n",
    "    features, target, train_size=0.2, stratify=target\n",
    ")\n",
    "\n",
    "val_X, test_X, val_target, test_target = model_selection.train_test_split(\n",
    "    val_X, val_target, train_size=0.5, stratify=val_target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import ClusterNodeGenerator\n",
    "        \n",
    "generator = ClusterNodeGenerator(G, clusters=24, q=24,  name='generator') # q: clusters per batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_flow = generator.flow(tr_target.index, tr_target, name='train') # node_id, target\n",
    "val_flow = generator.flow(val_target.index, val_target, name='val')\n",
    "test_flow = generator.flow(test_target.index, test_target, name='test')\n",
    "tot_flow = generator.flow(target.index, target, name='tot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.layer import ClusterGCN\n",
    "import tensorflow.keras.backend as K\n",
    "# like keras models\n",
    "gcn = ClusterGCN(layer_sizes=[32, 32], activations=[LeakyReLU(0.3), LeakyReLU(0.3)], generator=generator, dropout=0.3)\n",
    "\n",
    "# build network\n",
    "nc_inp, nc_out = gcn.build()\n",
    "\n",
    "nc_layer = layers.Dense(16, activation=LeakyReLU(0.3))(nc_out)\n",
    "nc_layer = layers.Dense(1, activation='sigmoid')(nc_layer)\n",
    "\n",
    "nc_model = Model(inputs=nc_inp, outputs=nc_layer)\n",
    "nc_model.compile(\n",
    "    optimizer=optimizers.Adam(lr=1e-3),\n",
    "    loss=losses.binary_crossentropy,\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "\n",
    "pred_layer = layers.Lambda(lambda x: K.squeeze(x, 0))(nc_layer)\n",
    "pred_model = Model(nc_inp, pred_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inject a few layer(FC) to better do ML things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor='val_acc')\n",
    "nc_hist = nc_model.fit(tr_flow, epochs=200,\n",
    "                validation_data=val_flow,\n",
    "                shuffle=False, # should be False!!\n",
    "                callbacks=[es],\n",
    "                verbose=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(nc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_micro = f1_score(test_target.values, list(map(lambda x: 1 if x>0.5 else 0, (nc_model.predict(test_flow).squeeze()))), average='micro')\n",
    "f1_marco = f1_score(test_target.values, list(map(lambda x: 1 if x>0.5 else 0, (nc_model.predict(test_flow).squeeze()))), average='macro')\n",
    "\n",
    "print('f1_micro:', round(f1_micro,3), '\\nf1_macro:', round(f1_marco, 3)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison with non-graph classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression().fit(features.loc[tr_target.index], tr_target)\n",
    "\n",
    "f1_micro = f1_score(test_target.values, lr.predict(features.loc[test_target.index]), average='micro')\n",
    "f1_macro = f1_score(test_target.values, lr.predict(features.loc[test_target.index]), average='macro')\n",
    "\n",
    "print('f1_micro:', round(f1_micro,3), '\\nf1_macro:', round(f1_marco, 3)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize how it classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = Model(nc_inp, nc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_x = tsne.fit_transform(emb_model.predict(tot_flow).squeeze())\n",
    "\n",
    "lbe = preprocessing.LabelEncoder()\n",
    "col = lbe.fit_transform(target)\n",
    "\n",
    "alpha = 0.7\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    tsne_x[:, 0],\n",
    "    tsne_x[:, 1],\n",
    "    cmap=\"rainbow\",\n",
    "    c=col,\n",
    "    alpha=alpha,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
